{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Synthetic Data with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from claudette import *\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from fastcore.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = Client(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = Path.cwd() ; print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(FP/'.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationCritique(BasicRepr):\n",
    "    \"A critique of the translation.\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        critique: str, # A brief 1-line critique of the translation.\n",
    "        score: int # A score of the translation from 1 to 5. \n",
    "    ): store_attr()\n",
    "    \n",
    "    __repr__ = basic_repr('critique, score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = \"As an expert radiologist, evaluate synthetic radiology reports for accuracy and quality, focusing on findings related to calcifications, including microcalcifications. Consider the description, size, distribution, and potential clinical significance of any calcifications mentioned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FP/'data/claude3-opus-microcalcs-n610.csv')\n",
    "# df_sampled = df.sample(n=15) # can set random_seed=42 IF you want to be consistent with the sampling\n",
    "# df_sampled.head()\n",
    "# df_sampled.label.value_counts()\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report():\n",
    "    \"Radiology Report + Label\"\n",
    "    def __init__(self, report: str, label: str): store_attr()\n",
    "    def __repr__(self): return f\"{self.report} âž¡ *{self.label}*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_reports = [Report(report, label) for report, label in zip(df.report_text, df.label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_reports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(example_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clps_fmt = '- {s}\\n\\n<details>\\n<summary> Click to show the rest </summary>\\n{ls}\\n</details>'\n",
    "def to_md(ss, collapsible=False):\n",
    "    ls = '\\n'.join(f'- {s}' for s in ss) \n",
    "    return clps_fmt.format(s=str(ss[0]), ls=ls.replace(f'- {ss[0]}', '')) if collapsible else ls\n",
    "def show(ss, collapsible=False): return Markdown(to_md(ss, collapsible=collapsible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(example_reports, collapsible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(pr): return cli.structured(pr, temp=1, tools=TranslationCritique)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt_template = \"\"\"\\\n",
    "    Below is a report with the following label {label}. The label indicates whether the report mentions:\n",
    "    - a positive finding for calcifications (including microcalcifications)\n",
    "    - a negative finding for calcifications (explicitly stating no calcifications were found)\n",
    "    - or does not discuss calcifications at all (truly not mentioning calcifications in any way)\n",
    "\n",
    "    Important: Any explicit mention of calcifications, even to state their absence, should be considered a negative finding, not a \"Not Stated\" case.\n",
    "\n",
    "    Evaluate its quality as a senior radiologist would, considering its suitability for professional use. Use the additive 5-point scoring system described below. Points are accumulated based on the satisfaction of each criterion:\n",
    "\n",
    "    - Award 1 point if the report's content is correctly aligned with the given label regarding calcifications (including microcalcifications). Remember, explicitly stating no calcifications were found is a negative finding, not a \"Not Stated\" case.\n",
    "    - Add another point if the report accurately conveys basic radiological findings related to calcifications (or their absence), distinguishing between microcalcifications and larger calcifications when relevant, but may have minor errors.\n",
    "    - Award a third point if the report uses correct terminology for both calcifications and microcalcifications, is appropriate for professional use, and demonstrates good understanding of radiological principles.\n",
    "    - Grant a fourth point if the report is highly accurate, reads naturally, and effectively handles complex concepts related to calcifications and microcalcifications with clear descriptions of their size, distribution, and potential significance.\n",
    "    - Bestow a fifth point if the report is outstanding, demonstrating mastery of clinical language and radiological expertise, capturing subtle nuances of calcification appearance and distribution, maintaining a professional tone, and providing appropriate recommendations for further evaluation if necessary.\n",
    "\n",
    "    <report>\n",
    "    {report}\n",
    "    </report>\n",
    "\n",
    "    After examining the report:\n",
    "\n",
    "    - Briefly justify your total score in a single line.\n",
    "    - Conclude with the score of the report.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critique(r):\n",
    "    critique = synthesize(eval_prompt_template.format(report=r.report, label=r.label))\n",
    "    return (r.report, r.label, critique.critique, critique.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [get_critique(r) for r in example_reports]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiqued = pd.DataFrame(results, columns=['report_text', 'label', 'critique', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiqued.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "df_critiqued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critiqued.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "df_poor = df_critiqued[df_critiqued['score'] <= 3].reset_index(drop=True)\n",
    "df_poor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "df_great = df_critiqued[df_critiqued['score'] == 5].reset_index(drop=True)\n",
    "df_great.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_critiqued.to_csv('microcalcs-n610-claude-3-opus-20240229-critiqued.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
